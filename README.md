# ğŸµ Musem Project â€” Emotion-Aware Music Recommendation Chatbot ğŸ¤–

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Librosa](https://img.shields.io/badge/Audio-Librosa-orange.svg)](https://librosa.org/)
[![SVM](https://img.shields.io/badge/Model-SVM-green.svg)](https://scikit-learn.org/)
[![Gradio](https://img.shields.io/badge/UI-Gradio-yellow.svg)](https://gradio.app/)
[![License](https://img.shields.io/badge/License-MIT-lightgrey.svg)](LICENSE)

---

## ğŸ§© Overview
**Musem (Music + Emotion)** is an AI-powered chatbot that recommends songs based on the userâ€™s **current emotion**, detected directly from their **voice**.  
By analyzing vocal features, Musem suggests music that helps users **manage emotions**, **relax**, or **uplift** their mood.

---

## âœ¨ Features
- ğŸ™ **Voice Emotion Detection:**  
  Detects user emotion using an **SVM model** trained on the **RAVDESS Emotional Speech Audio** dataset.

- ğŸ§ **Personalized Music Recommendation:**  
  Suggests songs from **Spotify mood data**, categorized by features like *valence*, *energy*, and *tempo*.

- ğŸ’¬ **Interactive Chatbot:**  
  Built with **Gradio**, supporting both **text** and **voice** conversations.

- ğŸ§  **AI Reasoning Engine:**  
  Integrated with **Gemini AI + RAG** for emotion-aware contextual responses.

- ğŸ”Š **Natural Voice Interaction:**  
  Uses `SpeechRecognition` for voice input and `gTTS` (Google Text-to-Speech) for output.

---

## âš™ï¸ Technical Summary
| Component | Description |
|------------|--------------|
| **Feature Extraction** | MFCCs via `librosa` |
| **Model** | Support Vector Machine (RBF kernel) |
| **Optimization** | GridSearchCV with Stratified K-Fold |
| **Metrics** | Precision, Recall, F1, Accuracy |
| **Accuracy** | â‰ˆ 71% (Macro-F1: 0.70) |
| **Frontend** | Gradio Web Interface |
| **Deployment** | Localhost / Web Demo |

---

## ğŸ” Ethics & Privacy
Musem addresses the ethical challenges of AI in mental-health applications:

- ğŸ”’ **Data Privacy:**  
  Anonymizes user data and minimizes personal data collection.

- âš–ï¸ **Transparency:**  
  Clearly informs users that Musem is an **AI assistant**, *not a therapist*.

- ğŸ§© **Bias Mitigation:**  
  Ensures diverse, balanced datasets and regular audits for bias.

- ğŸš¨ **Safety Measures:**  
  Provides disclaimers and emergency guidance for sensitive user contexts.

---

## ğŸš€ Future Development
- Train on **larger multilingual datasets** for emotion recognition.
- Integrate **NLP emotion understanding** from speech content.
- Replace rule-based music recommendation with a **deep learning recommender**.
- Deploy with **Flask** for improved UI/UX and chat history.
- Extend recommendations to **movies, books, and activities**.

---

## ğŸ§‘â€ğŸ’» Team
| Name | Student ID |
|------|-------------|
| **LÃª PhÃº Trá»ng** | BDAI-011 |
| **Pháº¡m VÄƒn Minh PhÃºc** | BDAI-021 |
| **VÅ© Gia Báº£o** | BDAI-045 |
| **Nguyá»…n VÅ© An VÆ°á»£ng** | BDAI-055 |
| **Nguyá»…n Pháº¡m Äá»©c Huy** | BDAI-056 |

ğŸ“ *Ho Chi Minh City, September 2025*

---

## ğŸ“š References
1. McFee et al. (2015). *Audio and Music Signal Analysis in Python (Librosa)*  
2. Davis & Mermelstein (1980). *Parametric Representations for Word Recognition*  
3. Scherer (2003). *Vocal Communication of Emotion*  
4. Juslin & Laukka (2003). *Emotion in Music and Vocal Expression*  
5. Banse & Scherer (1996). *Acoustic Profiles in Vocal Emotion Expression*

---

> ğŸ¶ *Musem â€” Where AI Listens, Understands, and Plays Your Emotions.*
